---
title: "Model_Selection"
author: "Kaija Gahm"
date: "2/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load libraries
```{r}
source("libraries.R")
```

# Load data
```{r}
load("data/outputs/stats_fast3.Rda") # this includes lab and wild tads
```

# Further data cleaning
## Code random effects explicitly
We should have used different letters for the individuals in the two temperature treatments, because strictly speaking we should have labeled the individuals before choosing which ones to put into which temperature treatment. We did select those randomly, but the naming scheme that we chose does not reflect that.

We don't want to change the letters on the tadpoles because that would make the data be out of sync with all of the labels on everything up to this point. Instead, we're going to stick with our scheme of appending "high" or "low" to the names to distinguish e.g. CPS_01_A in high/low treatments (since that is NOT the same individual.)
```{r}
stats_fast3 <- stats_fast3 %>% # remove tadpole column
  mutate(clutch = factor(paste(pond, clutch)), # code clutches explicitly
         indiv = factor(paste(clutch, indiv, treatment))) # code individuals explicitly
locate.nas(stats_fast3)

stats_fast3 <- stats_fast3 %>%
  mutate(burst_date = dmy(paste(burst_day, burst_month, burst_year, sep = "_")))
```

## Select relevant columns and change data types
```{r}
dat3 <- stats_fast3 %>% select(tadpole, trial, indiv, treatment, sline_speed_mm_s, PC1, PC2, pond, size, clutch, mass, gs, T_initial, camera, burst_date) %>% ungroup() %>% mutate(treatment = factor(treatment),
                     pond = factor(pond),
                     clutch = factor(clutch)) %>%
  filter(treatment %in% c("High", "Low"), !is.na(PC1)) %>% droplevels()

# wild tadpoles are separate
wild <- stats_fast3 %>% select(tadpole, trial, treatment, sline_speed_mm_s, PC1, PC2, pond, size, mass, gs, T_initial, camera, burst_date) %>% ungroup() %>% mutate(treatment = factor(treatment),
                     pond = factor(pond)) %>% 
  filter(treatment == "Wild") %>% droplevels()

# fix NA's for pond
wild %>% filter(is.na(pond))
wild$pond[is.na(wild$pond)] <- str_extract(wild$tadpole[is.na(wild$pond)], pattern = "(?<=^)[[:upper:]]{2,3}(?=\\_)")
```

## Export the data for modeling
```{r}
save(dat3, file = "data/outputs/dat3.Rda")
save(wild, file = "data/outputs/wild.Rda")
```

## Remove NA's
### Wild 
#### Remove NA's
```{r}
wild_nonas <- wild[complete.cases(wild),] # remove NA's
wild_nonas <- wild_nonas %>% filter(!is.na(T_initial), !is.na(mass))
```

#### Add pond temps
```{r}
## Add pond temps
load("data/outputs/pond_avg_temps.Rda") # Load pond temperatures
wild_nonas <- wild_nonas %>% left_join(pond_avg_temps, by = "pond")

## Add all relevant dates
load("data/outputs/wild_dates.Rda")
wild_dates <- wild_dates %>%
  select(-pond) # remove pond before joining

wild_nonas <- wild_nonas %>% # join dates
  left_join(wild_dates, by = "tadpole")

locate.nas(wild_nonas) # check for NA's
```

#### Add mass at stage
```{r}
# Predict mass from gosner stage
mass_gs_mod_wild <- lm(mass ~ gs, data = wild_nonas)
wild_nonas <- wild_nonas %>%
  mutate(mass_at_stage = resid(mass_gs_mod_wild))
```


#### Save wild_nonas
```{r}
save(wild_nonas, file = "data/outputs/wild_nonas.Rda")
```

### Lab-reared
#### Remove NA's
```{r}
dat3_nonas <- dat3 %>% filter(!is.na(T_initial) & !is.na(mass))
locate.nas(dat3_nonas)
```

#### Add incubator temps
```{r}
load("data/outputs/avg_inc_temps.Rda") # Load pond temperatures
dat3_nonas <- dat3_nonas %>% left_join(avg_inc_temps, by = "treatment") %>%
  mutate(treatment = factor(treatment))

locate.nas(dat3_nonas) # check for NA's
```

#### Add mass at stage
```{r}
# Predict mass from gosner stage
mass_gs_mod <- lm(mass ~ gs, data = dat3_nonas)
dat3_nonas <- dat3_nonas %>%
  mutate(mass_at_stage = resid(mass_gs_mod))
```

#### Save dat3_nonas
```{r}
save(dat3_nonas, file = "data/outputs/dat3_nonas.Rda")
```

# Mixed modeling
Hierarchical mixed model, incorporating pond within clutch and accounting for multiple trials per individual
Dat3: fastest 3 trials per tadpole

## Establish random effect structure
```{r}
mod1 <- lmer(sline_speed_mm_s ~ treatment * mass + (1|pond/clutch) + (1|indiv) + (1|camera), data = dat3_nonas)
summary(mod1)

# without the camera
modx <- lmer(sline_speed_mm_s ~ treatment * mass + (1|pond/clutch) + (1|indiv), data = dat3_nonas)
summary(modx)

# exclude mass and camera
modpond <- lmer(sline_speed_mm_s ~ treatment + (1|pond/clutch) + (1|indiv), data = dat3_nonas)
summary(modpond)

# remove indiv
modpond2 <- lmer(sline_speed_mm_s ~ treatment + (1|pond/clutch), data = dat3_nonas)
summary(modpond2)

# removing the pond and camera random effects, because they don't tell us much. In fact, we need to remove the pond effect to get a non-singular fit.
mod3 <- lmer(sline_speed_mm_s ~ treatment * mass + (1|clutch/indiv), data = dat3_nonas) # use this syntax, but remember that clutch already accounts for being nested thin pond. 
# note that if we add camera to this model, it doesn't converge.

# : specifies that clutch is nested within pond, but without first fitting pond (since we discovered we don't need to)
# / explicitly fits pond first and then clutch.

dat3_nonas$predicted_speed <- predict(mod1, re.form = NA, newdata = dat3_nonas)
dat3_nonas$predicted_speed_withresids <- predict(mod1, re.form = NA, newdata = dat3_nonas) + resid(mod1, newdata = dat3_nonas)
```

## Check random effect structure
```{r}
# Compare ggplots
dat3_nonas %>% ggplot(aes(x = mass, y = sline_speed_mm_s, col = treatment))+
  geom_point()+
  geom_smooth(method = "lm")+
  ylab("speed (mm/s)")+
  ggtitle("Original data")

dat3_nonas %>% ggplot(aes(x = mass, y = predicted_speed, col = treatment))+
  geom_point()+
  geom_smooth(method = "lm")+
  ylab("predicted_speed (mm/s)")+
  ggtitle("Predicted data")

dat3_nonas %>% ggplot(aes(x = mass, y = predicted_speed_withresids, col = treatment))+
  geom_point()+
  geom_smooth(method = "lm")+
  ylab("predicted_speed_withresids (mm/s)")+
  ggtitle("Predicted data with residuals")
```
The similarity between these graphs shows us that we have correctly specified the structure of our random effects


## Main effects
### Investigate correlations
```{r}
#dat3_nonas %>% select(PC1, PC2, size, mass, gs, T_initial, treatment) %>% ggpairs()
```
Size, mass, and gosner stage are all closely correlated. 

### Standardize variables
```{r}
# Function to calculate z scores
standardize <- function(vector){
  mu <- mean(vector)
  sd <- sd(vector)
  z_vector <- (vector-mu)/sd
  return(z_vector)
}

dat3_nonas_std <- dat3_nonas %>% mutate_at(.vars = c("PC1", "PC2", "mass", "size", "gs", "T_initial", "mass_at_stage"), standardize)
save(dat3_nonas_std, file = "data/outputs/dat3_nonas_std.Rda")
```

## Select variables
We know from various papers that shape, development, size (mass), temperature water during the trial affect burst speed.
Variables:
 - Tadpole mass (as a measure of size)
 - Temperature treatment (as a measure of developmental/growth rate)
 - Gosner stage (as a measure of development)
 - Tray temperature (experimental conditions)
 
The performance at any given mass or GS may be impacted by the developmental rate, so we'll allow for temp_treatment:mass and temp_treatment:gs. Tray temperature varied so little between the two temperature treatments that we didn't consider an interaction there, including only the additive effect.
```{r}
dat3_nonas %>%
  ggplot(aes(x = T_initial, col = treatment))+
  geom_density()

dat3_nonas %>%
  ggplot(aes(x = T_initial, y = sline_speed_mm_s, col = treatment))+
  geom_point()+
  geom_smooth(method = "lm") # ok yeah we definitely do not need an interaction term here.
```

### Shape variables
Independent of body size
We can use either PC1 (ratio of body length to total length) or PC2 (ratio of depth to length)
Because they're principal components, they're orthogonal. Neither is particularly strongly correlated with mass or Gosner stage.
Which is a better predictor of speed?
```{r}
dat3_nonas %>% ggplot(aes(x = PC1, y = sline_speed_mm_s, col = treatment))+
  geom_point()+
  geom_smooth(method = "lm")

dat3_nonas %>% ggplot(aes(x = PC2, y = sline_speed_mm_s, col = treatment))+
  geom_point()+
  geom_smooth(method = "lm")

# PC2 appears to be a slightly better predictor of speed.
```
We'll use PC2 for now, and then we'll compare models later on to see which is better once other variables are taken into account.

## Model selection
### Fit several full models
Using unstandardized values for now.
```{r}
load("data/outputs/dat3_nonas_std.Rda")
full_3way <- lmer(sline_speed_mm_s ~ treatment*mass*gs + PC2 + T_initial + (1|pond/clutch/tadpole), data = dat3_nonas_std, REML = F)

full <- lmer(sline_speed_mm_s ~ treatment*mass + treatment*gs + PC2 + T_initial + (1|pond/clutch/tadpole), data = dat3_nonas_std, REML = F)

full_alt <- lmer(sline_speed_mm_s ~ treatment + mass*gs + PC2 + T_initial + (1|pond/clutch/tadpole), data = dat3_nonas_std, REML = F)

resid <- lmer(sline_speed_mm_s ~ mass_at_stage*treatment + gs*treatment + PC2 + T_initial + (1|pond/clutch/tadpole), data = dat3_nonas_std, REML = F)
summary(resid) 
# We've decided to use this one: AIC is the same as the full model, but it's more interpretable.

#AIC comparison
AIC(full_3way, full, full_alt, resid) %>%
  mutate(model = row.names(.)) %>%
  arrange(AIC)
```

### Select a model
Because it's most interpretable and has one of the lowest AIC's (equivalent to the full model including mass), we're going to select the model that uses size-at-stage, the residual of mass on gosner stage. 
```{r}
consensus_mod_std <- resid
save(consensus_mod_std, file = "data/outputs/consensus_mod_std.Rda")

summary(consensus_mod_std)

# Get R-squared
MuMIn::r.squaredGLMM(consensus_mod_std)

# Confidence intervals for the coefficients
#ci <- confint.merMod(consensus_mod, method = "boot", nsim = 1000, oldNames = FALSE)
```


#### Re-fit the  model with unstandardized vars
```{r}


consensus_mod <- lmer(sline_speed_mm_s ~ mass_at_stage*treatment + gs*treatment + PC2 + T_initial + (1|pond/clutch/tadpole), data = dat3_nonas)
summary(consensus_mod)

# Get R-squared
MuMIn::r.squaredGLMM(consensus_mod)

# Confidence intervals for the coefficients
#ci <- confint.merMod(consensus_mod, method = "boot", nsim = 1000, oldNames = FALSE)

save(consensus_mod, file = "data/outputs/consensus_mod.Rda")
summary(consensus_mod)
```


## Check residuals
```{r}
plot(consensus_mod) # looking good!
```

## Variance structure?
```{r}
# # this is how we fitted our original model, mod_gs
# formula(consensus_mod)
# summary(consensus_mod)
# 
# mod_nostruct <- lme(sline_speed_mm_s ~ mass*treatment + gs + T_initial,
#          random = ~ 1 | clutch/indiv,
#          data = dat3_nonas_std)
# summary(mod_nostruct)
# 
# mod_varfixed <- lme(sline_speed_mm_s ~ mass*treatment + gs + T_initial,
#          random = ~ 1 | clutch/indiv,
#          weights = varFixed(~gs),
#          data = dat3_nonas_std)
# summary(mod_varfixed)
# 
# mod_varident <- lme(sline_speed_mm_s ~ mass*treatment + gs + T_initial,
#          random = ~ 1 | clutch/indiv,
#          weights = varIdent(form = ~ 1 | factor(as.character(gs))),
#          data = dat3_nonas_std)
# 
# # mod_varpower <- lme(sline_speed_mm_s ~ mass*treatment + gs + T_initial,
# #          random = ~ 1 | clutch/indiv,
# #          weights = varPower(form = ~ gs),
# #          data = dat3_nonas)
# # summary(mod_varpower) # but we shouldn't use this, since gs can take a value of 0 once scaled.
# 
# mod_varexp <- lme(sline_speed_mm_s ~ mass*treatment + gs + T_initial,
#          random = ~ 1 | clutch/indiv,
#          weights = varExp(form = ~ gs),
#          data = dat3_nonas_std)
# summary(mod_varexp)
# 
# mod_varconstpower <- lme(sline_speed_mm_s ~ mass*treatment + gs + T_initial,
#          random = ~ 1 | clutch/indiv,
#          weights = varConstPower(form = ~ gs),
#          data = dat3_nonas_std)
# summary(mod_varconstpower)


#anova(mod_nostruct, mod_varfixed, mod_varident, mod_varexp, mod_varconstpower) # var_nostruct actually wins
```

### Save model with structure
```{r}
# consensus_mod_varident <- mod_varident
# save(consensus_mod_varident, file = "data/outputs/consensus_mod_varident")
```

# Wild tadpoles
## Standardize variables
```{r}
head(wild_nonas)
# Function to calculate z scores
standardize <- function(vector){
  mu <- mean(vector)
  sd <- sd(vector)
  z_vector <- (vector-mu)/sd
  return(z_vector)
}

wild_nonas_std <- wild_nonas %>% mutate_at(.vars = c("PC1", "PC2", "mass", "size", "gs", "T_initial", "avg_pond_temp", "mass_at_stage"), standardize)
save(wild_nonas_std, file = "data/outputs/wild_nonas_std.Rda")
```

## Model
### Standardized
```{r}
consensus_mod_wild_std <- lmer(sline_speed_mm_s ~ mass_at_stage*avg_pond_temp + gs*avg_pond_temp + PC2 + T_initial + (1|pond/tadpole), data = wild_nonas_std)
summary(consensus_mod_wild_std)

# Get R-squared
MuMIn::r.squaredGLMM(consensus_mod_wild_std)

# Confidence intervals for the coefficients
#ci <- confint.merMod(consensus_mod_wild_std, method = "boot", nsim = 1000, oldNames = FALSE)

save(consensus_mod_wild_std, file = "data/outputs/consensus_mod_wild_std.Rda")
```

### Unstandardized
```{r}
consensus_mod_wild <- lmer(sline_speed_mm_s ~ mass_at_stage*avg_pond_temp + gs*avg_pond_temp + PC2 + T_initial + (1|pond/tadpole), data = wild_nonas)
summary(consensus_mod_wild)

# Get R-squared
MuMIn::r.squaredGLMM(consensus_mod_wild)

save(consensus_mod_wild, file = "data/outputs/consensus_mod_wild.Rda")
```

