---
title: "Model_Selection"
author: "Kaija Gahm"
date: "2/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load libraries
```{r}
source("libraries.R")
```

# Load data
```{r}
load("data/outputs/stats_fast3.Rda")
```

# Further data cleaning
## Code random effects explicitly
We should have used different letters for the individuals in the two temperature treatments, because strictly speaking we should have labeled the individuals before choosing which ones to put into which temperature treatment. We did select those randomly, but the naming scheme that we chose does not reflect that.

We don't want to change the letters on the tadpoles because that would make the data be out of sync with all of the labels on everything up to this point. Instead, we're going to stick with our scheme of appending "high" or "low" to the names to distinguish e.g. CPS_01_A in high/low treatments (since that is NOT the same individual.)
```{r}
stats_fast3 <- stats_fast3 %>% # remove tadpole column
  mutate(clutch = factor(paste(pond, clutch)), # code clutches explicitly
         indiv = factor(paste(clutch, indiv, treatment))) # code individuals explicitly
locate.nas(stats_fast3)
```

## Select relevant columns and change data types
```{r}
dat3 <- stats_fast3 %>% select(tadpole, trial, indiv, treatment, sline_speed_mm_s, PC1, PC2, pond, size, clutch, mass, gs, T_initial, camera) %>% ungroup() %>% mutate(treatment = factor(treatment),
                     pond = factor(pond),
                     clutch = factor(clutch)) %>%
  filter(treatment %in% c("High", "Low"), !is.na(PC1)) %>% droplevels()

# wild tadpoles are separate
wild <- stats_fast3 %>% select(tadpole, trial, treatment, sline_speed_mm_s, PC1, PC2, pond, size, mass, gs, T_initial, camera) %>% ungroup() %>% mutate(treatment = factor(treatment),
                     pond = factor(pond)) %>% 
  filter(treatment == "Wild") %>% droplevels()

# fix NA's for pond
wild %>% filter(is.na(pond))
wild$pond[is.na(wild$pond)] <- str_extract(wild$tadpole[is.na(wild$pond)], pattern = "(?<=^)[[:upper:]]{2,3}(?=\\_)")
```

## Export the data for modeling
```{r}
save(dat3, file = "data/outputs/dat3.Rda")
save(wild, file = "data/outputs/wild.Rda")
```

# Mixed modeling
Hierarchical mixed model, incorporating pond within clutch and accounting for multiple trials per individual
Dat3: fastest 3 trials per tadpole

## Establish random effect structure
```{r}
mod1 <- lmer(sline_speed_mm_s ~ treatment * mass + (1|pond/clutch) + (1|indiv) + (1|camera), data = dat3)
summary(mod1)

# without the camera
modx <- lmer(sline_speed_mm_s ~ treatment * mass + (1|pond/clutch) + (1|indiv), data = dat3)
summary(modx)

# exclude mass and camera
modpond <- lmer(sline_speed_mm_s ~ treatment + (1|pond/clutch) + (1|indiv), data = dat3)
summary(modpond)

# remove indiv
modpond2 <- lmer(sline_speed_mm_s ~ treatment + (1|pond/clutch), data = dat3)
summary(modpond2)

?lmer

# removing the pond and camera random effects, because they don't tell us much. In fact, we need to remove the pond effect to get a non-singular fit.
mod3 <- lmer(sline_speed_mm_s ~ treatment * mass + (1|clutch/indiv), data = dat3) # use this syntax, but remember that clutch already accounts for being nested thin pond. 
# note that if we add camera to this model, it doesn't converge.

# : specifies that clutch is nested within pond, but without first fitting pond (since we discovered we don't need to)
# / explicitly fits pond first and then clutch.

dat3$predicted_speed <- predict(mod1, re.form = NA, newdata = dat3)
dat3$predicted_speed_withresids <- predict(mod1, re.form = NA, newdata = dat3) + resid(mod1, newdata = dat3)
```

## Check random effect structure
```{r}
# Compare ggplots
dat3 %>% ggplot(aes(x = mass, y = sline_speed_mm_s, col = treatment))+
  geom_point()+
  geom_smooth(method = "lm")+
  ylab("speed (mm/s)")+
  ggtitle("Original data")

dat3 %>% ggplot(aes(x = mass, y = predicted_speed, col = treatment))+
  geom_point()+
  geom_smooth(method = "lm")+
  ylab("predicted_speed (mm/s)")+
  ggtitle("Predicted data")

dat3 %>% ggplot(aes(x = mass, y = predicted_speed_withresids, col = treatment))+
  geom_point()+
  geom_smooth(method = "lm")+
  ylab("predicted_speed_withresids (mm/s)")+
  ggtitle("Predicted data with residuals")
```
The similarity between these graphs shows us that we have correctly specified the structure of our random effects


## Figure out main effects
### Investigate correlations
```{r}
#dat3 %>% select(PC1, PC2, size, mass, gs, T_initial, treatment) %>% ggpairs()
```
Size, mass, and gosner stage are all closely correlated. 

## Remove observations that are NA for mass
```{r}
dat3 <- dat3 %>% filter(!is.na(mass))
```

### Remove NA's
```{r}
dat3_nonas <- dat3 %>% filter(!is.na(T_initial))
save(dat3_nonas, file = "data/outputs/dat3_nonas.Rda")
```

### Standardize variables
```{r}
# Function to calculate z scores
standardize <- function(vector){
  mu <- mean(vector)
  sd <- sd(vector)
  z_vector <- (vector-mu)/sd
  return(z_vector)
}

dat3_nonas <- dat3_nonas %>% mutate_at(.vars = c("PC1", "PC2", "mass", "size", "gs", "T_initial"), standardize)
```

## Make some biological decisions
In all of the tests that we ran, PC1 and PC2 were kind of equivalent (but with slightly more effect of PC2 than PC1), and mass and size were also basically equivalent. Therefore, we choose:
1. PC2 over PC1
2. mass over size: since they're pretty much the same anyway, this shouldn't change the results. Mass was calculated by weighing the tadpoles, whereas size was calculated from the same landmarks used to calculate the shape PC's: seems more indirect, so we'll go with mass. Mass is also more of a real biological phenomenon. Size would basically end up being the area of a cross section of the tadpole, which is probably not as important for physiological processes as mass. The two are also highly correlated, so we don't want both in the model.

## Model selection
### Fit full model
```{r}
full <- lmer(sline_speed_mm_s ~ PC2*mass*gs*treatment + T_initial + (1|clutch/indiv),
             data = dat3_nonas, na.action = "na.fail", REML = F)
vif(full) # check variance inflation factors: kind of high, but we're also going to be removing some of the interaction terms. Doesn't look too bad for the individual terms, especially because we already know that mass and gosner stage are correlated.

#dredge_full <- dredge(full)
#save(dredge_full, file = "data/outputs/dredge_full.Rda")

# Look at top five, see if the actual results for treatment effect are changing. If not, then we just know that we're accounting for the variables of interest. Provide table in supplements. 
```

### Fit top five models
```{r}
load("data/outputs/dredge_full.Rda") # load the dredge output
dredge_full[1:5,] # take a look at the top five models

m1 <- lmer(sline_speed_mm_s ~ mass*treatment + gs + T_initial + 
             (1 | clutch/indiv), data = dat3_nonas, REML = F, 
    na.action = "na.fail")
summary(m1)

m2 <- lmer(sline_speed_mm_s ~ mass*treatment + PC2 + gs + T_initial + 
             (1 | clutch/indiv), data = dat3_nonas, REML = F, 
    na.action = "na.fail")

m3 <- lmer(sline_speed_mm_s ~ mass*treatment + gs*mass + T_initial + 
             (1 | clutch/indiv), data = dat3_nonas, REML = F, 
    na.action = "na.fail")

m4 <- lmer(sline_speed_mm_s ~ treatment*gs + T_initial + 
             (1 | clutch/indiv), data = dat3_nonas, REML = F, 
    na.action = "na.fail")

m5 <- lmer(sline_speed_mm_s ~ mass*treatment + gs*mass + PC2 + T_initial + 
             (1 | clutch/indiv), data = dat3_nonas, REML = F, na.action = "na.fail")

# all of these have singular fits! Is that a problem?
```

### Create new df of means
```{r}
newdf <- dat3_nonas %>% select(treatment, clutch, indiv) # select grouping cols
newdf_means <- dat3_nonas %>% summarize(mass = mean(mass), # take mean of each
                                        gs = mean(gs),
                                        T_initial = mean(T_initial),
                                        PC2 = mean(PC2))
newdf[,4:7] <- newdf_means # bind grouping cols to means
newdf <- newdf %>% mutate(model1 = predict(m1, newdf), # predict on means with each model
                          model2 = predict(m2, newdf),
                          model3 = predict(m3, newdf),
                          model4 = predict(m4, newdf),
                          model5 = predict(m5, newdf))

df_preds <- newdf %>% select(treatment, model1, model2, model3, model4, model5) %>% 
  pivot_longer(cols = c(model1, model2, model3, model4, model5), # put into long format
               names_to = "model",
               values_to = "predicted_speed")

# Boxplot of predictions on means
df_preds %>% ggplot(aes(x = treatment, y = predicted_speed, fill = treatment))+
  geom_boxplot()+
  facet_wrap(~model)+
  ggtitle("Comparison of top 5 models, predicted on means of data")
```

## Select a model
Since all of the top 5 basically give the same results, we're going to choose model 1. 
```{r}
consensus_mod <- m1

# Get R-squared
MuMIn::r.squaredGLMM(consensus_mod)

# Confidence intervals for the coefficients
#confint.merMod(consensus_mod, method = "boot", nsim = 1000, oldNames = FALSE)

save(consensus_mod, file = "data/outputs/consensus_mod.Rda")
summary(consensus_mod)
```

## Check residuals
```{r}
dat3_nonas <- dat3_nonas %>% mutate(resid = resid(consensus_mod))
formula(consensus_mod)

dat3_nonas %$% qqnorm(resid)
plot(consensus_mod) # looks roughly normal, but just to make sure, we'll do individual plots

dat3_nonas %>% ggplot(aes(x = gs, y = resid))+
  geom_point() +
  facet_wrap(~treatment) # the gosner stage data violates the equal variance assumption

dat3_nonas %>% ggplot(aes(x = T_initial, y = resid))+
  geom_point() +
  facet_wrap(~treatment)

dat3_nonas %>% ggplot(aes(x = resid, col = treatment))+
  geom_density(aes(fill = treatment), alpha = 0.5)
```

## Add variance structure
```{r}
# this is how we fitted our original model, mod_gs
formula(consensus_mod)

mod_nostruct <- lme(sline_speed_mm_s ~ mass*treatment + gs + T_initial, 
         random = ~ 1 | clutch/indiv, 
         data = dat3_nonas)
summary(mod_nostruct)

mod_varfixed <- lme(sline_speed_mm_s ~ mass*treatment + gs + T_initial, 
         random = ~ 1 | clutch/indiv,
         weights = varFixed(~gs),
         data = dat3_nonas)
summary(mod_varfixed)

mod_varident <- lme(sline_speed_mm_s ~ mass*treatment + gs + T_initial,
         random = ~ 1 | clutch/indiv,
         weights = varIdent(form = ~ 1 | factor(as.character(gs))),
         data = dat3_nonas)

# mod_varpower <- lme(sline_speed_mm_s ~ mass*treatment + gs + T_initial, 
#          random = ~ 1 | clutch/indiv,
#          weights = varPower(form = ~ gs),
#          data = dat3_nonas)
# summary(mod_varpower) # but we shouldn't use this, since gs can take a value of 0 once scaled.

mod_varexp <- lme(sline_speed_mm_s ~ mass*treatment + gs + T_initial, 
         random = ~ 1 | clutch/indiv,
         weights = varExp(form = ~ gs),
         data = dat3_nonas)
summary(mod_varexp)

mod_varconstpower <- lme(sline_speed_mm_s ~ mass*treatment + gs + T_initial, 
         random = ~ 1 | clutch/indiv,
         weights = varConstPower(form = ~ gs),
         data = dat3_nonas)
summary(mod_varconstpower)


anova(mod_nostruct, mod_varfixed, mod_varident, mod_varexp, mod_varconstpower) # var_nostruct actually wins
```

# Save model with structure
```{r}
# consensus_mod_varident <- mod_varident
# save(consensus_mod_varident, file = "data/outputs/consensus_mod_varident")
```

# Wild tadpoles
## Load data
```{r}
load("data/outputs/wild_nonas.Rda")
```

## Add pond temps
```{r}
load("data/outputs/wild_tad_temps.Rda") # Load wild tadpole pond temperatures
head(wild_tad_temps)
wild_tad_temps_tojoin <- wild_tad_temps %>% select(tadpole, avg_pond_temp)
locate.nas(wild_tad_temps_tojoin) # check for NA's: looks good

wild_nonas <- wild_nonas %>% left_join(wild_tad_temps_tojoin, by = "tadpole")
```

## Model selection
### Variable standardization
```{r}
# Function to calculate z scores
standardize <- function(vector){
  mu <- mean(vector)
  sd <- sd(vector)
  z_vector <- (vector-mu)/sd
  return(z_vector)
}

wild_nonas <- wild_nonas %>% mutate_at(.vars = c("PC1", "PC2", "mass", "size", "gs", "T_initial", "avg_pond_temp"), standardize)
```

### Re-create consensus model: does it work for wild tads?
```{r}
load("data/outputs/consensus_mod.Rda")
formula(consensus_mod)
wild_mod <- lmer(sline_speed_mm_s ~ mass * avg_pond_temp + gs + T_initial + (1 | tadpole), 
                 data = wild_nonas, REML = F,
                 na.action = "na.fail")
summary(wild_mod)
vif(wild_mod) # Variance inflation factors look okay.
```

### Dredging
```{r}
# Full model, with no pond effect
full <- lmer(sline_speed_mm_s ~ PC2*mass*gs*avg_pond_temp + T_initial + (1 | tadpole),
             data = wild_nonas, 
             na.action = "na.fail", 
             REML = F)
# Do the same mean-based analysis on this one as I did for the lab-reared tadpoles. 
# What impact does the lab experiment have in the wild? Significance. 

# Dredge full model
#wild_full_dredge <- dredge(full)
#save(wild_full_dredge, file = "data/outputs/wild_full_dredge.Rda")
```

### Fit top five models
```{r}
load("data/outputs/wild_full_dredge.Rda")
wild_full_dredge[1:5,] # take a look at the top five models

m1 <- lmer(sline_speed_mm_s ~ mass + (1 | tadpole), data = wild_nonas, REML = F, 
           na.action = "na.fail")

m2 <- lmer(sline_speed_mm_s ~ mass + avg_pond_temp + (1 | tadpole), data = wild_nonas, REML = F, 
           na.action = "na.fail")

m3 <- lmer(sline_speed_mm_s ~ mass + PC2 + (1 | tadpole), data = wild_nonas, REML = F, 
           na.action = "na.fail")

m4 <- lmer(sline_speed_mm_s ~ gs + (1 | tadpole), data = wild_nonas, REML = F, 
           na.action = "na.fail")

m5 <- lmer(sline_speed_mm_s ~ mass + T_initial + (1 | tadpole), data = wild_nonas, REML = F, 
           na.action = "na.fail")
```

### Create new df of means
```{r}
wild_newdf <- wild_nonas %>% select(tadpole) # select grouping cols
newdf_means <- wild_nonas %>% summarize(mass = mean(mass), # take mean of each
                                      gs = mean(gs),
                                      T_initial = mean(T_initial),
                                      PC2 = mean(PC2),
                                      avg_pond_temp = mean(avg_pond_temp))

wild_newdf[,2:6] <- newdf_means # bind grouping cols to means
wild_newdf <- wild_newdf %>% mutate(model1 = predict(m1, wild_newdf), # predict on means with each model
                          model2 = predict(m2, wild_newdf),
                          model3 = predict(m3, wild_newdf),
                          model4 = predict(m4, wild_newdf),
                          model5 = predict(m5, wild_newdf))

wild_df_preds <- wild_newdf %>% select(model1, model2, model3, model4, model5) %>% 
  pivot_longer(cols = c(model1, model2, model3, model4, model5), # put into long format
               names_to = "model",
               values_to = "predicted_speed")

# Boxplot of predictions on means
wild_df_preds %>% ggplot(aes(y = predicted_speed))+
  geom_boxplot()+
  facet_wrap(~model)+
  ylab("predicted speed (mm/s)")+
  ggtitle("Comparison of top 5 models, predicted on means of data")
```

### Select top model
```{r}
# Select reduced model: best AIC
reduced_model <- lmer(sline_speed_mm_s ~ mass + (1 | tadpole),
                data = wild_nonas,
                na.action = "na.fail",
                REML = F)
summary(reduced_model)

# Get R-squared
MuMIn::r.squaredGLMM(reduced_model)

# Get confidence intervals for the coefficients
#confint.merMod(reduced_model, method = "boot", nsim = 1000, oldNames = FALSE)

consensus_mod_wild <- reduced_model
save(consensus_mod_wild, file = "data/outputs/consensus_mod_wild.Rda")

wild_nonas %>% ggplot(aes(x = mass, y = sline_speed_mm_s))+
  geom_point(alpha = 0.4)+
  geom_smooth(method = "lm", col = "black")+
  xlab("Mass")+
  ylab("Burst speed (mm/s)")
```
