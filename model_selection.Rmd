---
title: "Model_Selection"
author: "Kaija Gahm"
date: "2/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load data
```{r}
load("data/outputs/dat3.Rda")
```

# Mixed modeling
Hierarchical mixed model, incorporating pond within clutch and accounting for multiple trials per individual
Dat3: fastest 3 trials per tadpole

## Establish random effect structure
```{r}
mod1 <- lmer(sline_speed_m_s ~ treatment * mass + (1|pond/clutch) + (1|indiv), data = dat3)
summary(mod1)

# removing the pond random effect, because it doesn't tell us anything. In fact, we need to do this to get a non-singular fit.
mod2 <- lmer(sline_speed_m_s ~ treatment * mass + (1|pond:clutch) + (1|indiv), data = dat3)
mod3 <- lmer(sline_speed_m_s ~ treatment * mass + (1|clutch/indiv), data = dat3) # use this syntax, but remember that clutch already accounts for being nested within pond. 

# : specifies that clutch is nested within pond, but without first fitting pond (since we discovered we don't need to)
# / explicitly fits pond first and then clutch.


dat3$predicted_speed <- predict(mod1, re.form = NA, newdata = dat3)
dat3$predicted_speed_withresids <- predict(mod1, re.form = NA, newdata = dat3) + resid(mod1, newdata = dat3)
```

## Check random effect structure
```{r}
# Compare ggplots
dat3 %>% ggplot(aes(x = mass, y = sline_speed_m_s, col = treatment))+
  geom_point()+
  geom_smooth(method = "lm")+
  ylab("speed")+
  ggtitle("Original data")

dat3 %>% ggplot(aes(x = mass, y = predicted_speed, col = treatment))+
  geom_point()+
  geom_smooth(method = "lm")+
  ylab("predicted_speed")+
  ggtitle("Predicted data")

dat3 %>% ggplot(aes(x = mass, y = predicted_speed_withresids, col = treatment))+
  geom_point()+
  geom_smooth(method = "lm")+
  ylab("predicted_speed_withresids")+
  ggtitle("Predicted data with residuals")
```
The similarity between these graphs shows us that we have correctly specified the structure of our random effects


## Figure out main effects
### Investigate correlations
```{r}
dat3 %>% select(PC1, PC2, size, mass, gs, T_initial, treatment) %>% ggpairs()
```
Size, mass, and gosner stage are all closely correlated. 

## Remove observations that are NA for mass
```{r}
dat3 <- dat3 %>% filter(!is.na(mass))
```

### Remove NA's
```{r}
dat3_nonas <- dat3 %>% filter(!is.na(T_initial))
```

#[RE-DO THIS PART]: PC of size and mass, not gs. 
### PCA on size variables
```{r}
size_pca <- prcomp(dat3_nonas %>% select(gs, size, mass))
dat3_nonas$size_pc1 <- size_pca$x[,1]# put the size principal component into the data frame
size_pca
```

### Standardize variables
```{r}
# Function to calculate z scores
standardize <- function(vector){
  mu <- mean(vector)
  sd <- sd(vector)
  z_vector <- (vector-mu)/sd
  return(z_vector)
}

dat3_nonas <- dat3_nonas %>% mutate_at(.vars = c("PC1", "PC2", "mass", "size", "gs", "size_pc1", "T_initial"), standardize)
```


### Fit full models
```{r}
fullmodel_mass <- lmer(sline_speed_m_s ~ PC1*PC2*mass*treatment + T_initial + (1|clutch/indiv), data = dat3_nonas, na.action = "na.fail", REML = FALSE) 

fullmodel_size <- lmer(sline_speed_m_s ~ PC1*PC2*size*treatment + T_initial + (1|clutch/indiv), data = dat3_nonas, na.action = "na.fail", REML = FALSE)

fullmodel_gs <- lmer(sline_speed_m_s ~ PC1*PC2*gs*treatment + T_initial + (1|clutch/indiv), data = dat3_nonas, na.action = "na.fail", REML = FALSE) # SINGULAR

fullmodel_pc <- lmer(sline_speed_m_s ~ PC1*PC2*size_pc1*treatment + T_initial + (1|clutch/indiv), data = dat3_nonas, na.action = "na.fail", REML = FALSE) # SINGULAR
```



### Dredge full models
```{r}
#dredge_mass_best <- dredge(fullmodel_mass)[1,]
#dredge_size_best <- dredge(fullmodel_size)[1,]
#dredge_gs_best <- dredge(fullmodel_gs)[1,]
#dredge_pc_best <- dredge(fullmodel_pc)[1,]

#dredge_info_best <- list(dredge_mass_best, dredge_size_best, dredge_gs_best, dredge_pc_best)
#save(dredge_info_best, file = "data/outputs/dredge_info_best.Rda")

load("data/outputs/dredge_info_best.Rda")

# Make models from the info
dredge_info_best # look at the model selection table for the top models

# recreate the top models
mod_mass <- lmer(sline_speed_m_s ~ mass*treatment + PC2 + T_initial + (1 | clutch/indiv), data = dat3_nonas)

mod_size <- lmer(sline_speed_m_s ~ size*treatment + PC1 + T_initial + (1 | clutch/indiv), data = dat3_nonas)

mod_gs <- lmer(sline_speed_m_s ~ gs*treatment*PC1 + T_initial + (1 | clutch/indiv), data = dat3_nonas)

mod_pc <- lmer(sline_speed_m_s ~ PC1*treatment*size_pc1 + T_initial + (1 | clutch/indiv), data = dat3_nonas) # this one is singular

aic_table <- AIC(mod_mass, mod_size, mod_gs, mod_pc) %>% mutate(mod = row.names(.)) %>% arrange(AIC)
aic_table
```


## Try temperature as random effect
### Bin temperature by sd's
```{r}
# Create categorical temperature bins based on standard deviations
dat3_nonas <- dat3_nonas %>% mutate(tcat = cut(T_initial, seq(-3, 3, 1), right = FALSE, labels = c(1:6)))
```

### Re-fit full models
```{r}
tcat_mass <- lmer(sline_speed_m_s ~ PC1*PC2*mass*treatment + (1|clutch/indiv) + (1|tcat), data = dat3_nonas, na.action = "na.fail", REML = FALSE) # FAILED TO CONVERGE

tcat_size <- lmer(sline_speed_m_s ~ PC1*PC2*size*treatment + (1|clutch/indiv) + (1|tcat), data = dat3_nonas, na.action = "na.fail", REML = FALSE)

tcat_gs <- lmer(sline_speed_m_s ~ PC1*PC2*gs*treatment +  (1|clutch/indiv) + (1|tcat), data = dat3_nonas, na.action = "na.fail", REML = FALSE) # SINGULAR

tcat_pc <- lmer(sline_speed_m_s ~ PC1*PC2*size_pc1*treatment + (1|clutch/indiv) + (1|tcat), data = dat3_nonas, na.action = "na.fail", REML = FALSE) # SINGULAR


#tcat_mass_best <- dredge(tcat_mass)[1,]
#tcat_size_best <- dredge(tcat_size)[1,]
#tcat_gs_best <- dredge(tcat_gs)[1,]
#tcat_pc_best <- dredge(tcat_pc)[1,]

#tcat_info_best <- list(tcat_mass_best, tcat_size_best, tcat_gs_best, tcat_pc_best)
#save(tcat_info_best, file = "data/outputs/tcat_info_best.Rda")

load("data/outputs/tcat_info_best.Rda")

# Make models from the info
tcat_info_best # look at the model selection table for the top models

# recreate the top models
mod_mass_tcat <- lmer(sline_speed_m_s ~ mass*treatment + PC2 + (1 | clutch/indiv) + (1 | tcat), data = dat3_nonas) # failed to converge

mod_size_tcat <- lmer(sline_speed_m_s ~ size*treatment + PC1 + (1 | clutch/indiv) + (1 | tcat), data = dat3_nonas) # is singular

mod_gs_tcat <- lmer(sline_speed_m_s ~ PC1*treatment*gs + (1 | clutch/indiv) + (1 | tcat), data = dat3_nonas) # is singular

mod_pc_tcat <- lmer(sline_speed_m_s ~ PC1*treatment*size_pc1 + (1 | clutch/indiv) + (1 | tcat), data = dat3_nonas) # is singular

aic_table_tcat <- AIC(mod_mass_tcat, mod_size_tcat, mod_gs_tcat, mod_pc_tcat) %>% mutate(mod = row.names(.)) %>% arrange(AIC)
aic_table_tcat
```


Models with temperature as a categorical random effect either don't converge or are singular. Seems like we should not do this.

## Check for multicollinearity
```{r}
vif(fullmodel_size)
vif(fullmodel_mass)
vif(fullmodel_gs)
vif(fullmodel_pc)
```

## Check for normality
```{r}
dat3_nonas <- dat3_nonas %>% mutate(resid = resid(mod_gs))
dat3_nonas %$% qqnorm(resid) # looks good! 

mod_gs

head(dat3_nonas)
dat3_nonas %>% ggplot(aes(x = PC1, y = resid))+
  geom_point() +
  facet_wrap(~treatment)

dat3_nonas %>% ggplot(aes(x = jitter(gs), y = resid))+
  geom_point() +
  facet_wrap(~treatment)

dat3_nonas %>% ggplot(aes(x = T_initial, y = resid))+
  geom_point() +
  facet_wrap(~treatment)

dat3_nonas %>% ggplot(aes(x = resid, col = treatment))+
  geom_density(aes(fill = treatment), alpha = 0.5)
```

Identity variance structure: each gs gets its own variance
Var_exp: variance is an exponent of the variable
For all of this we have to refit with nlme.
Hard to fit variance structure on mean-standardized data
Var_power should still work on negative number. Can also do combinations of e.g. var_power and var_ident

## Select model
```{r}
consensus_mod <- mod_gs
summary(mod_gs)
save(consensus_mod, file = "data/outputs/consensus_mod.Rda")
```
